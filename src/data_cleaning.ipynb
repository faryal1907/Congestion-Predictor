{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7e5a156-6877-4428-a739-cbe025220747",
   "metadata": {},
   "source": [
    "# **Data Cleaning: Process Each Source Individually**\n",
    "**Run after:** data_exploration.ipynb.  \n",
    "**Outputs:** Cleaned CSVs in data/processed/ (accidents, mobility, weather, roads).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f02241-bc52-4435-afd5-b743a074eb77",
   "metadata": {},
   "source": [
    "## **Imports & Paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc2e661e-ff34-4092-8e26-282e33a2865e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Data Cleaning Started ===\n",
      "Raw path: ../data/raw/ (files: ['2020_PK_Region_Mobility_Report.xlsx', '2021_PK_Region_Mobility_Report.xlsx', '2022_PK_Region_Mobility_Report.xlsx', 'hotosm_pak_roads_lines_shp.dbf', 'hotosm_pak_roads_lines_shp.shp', 'hotosm_pak_roads_lines_shp.shx', 'pakistan_weather_2000_2024.csv', 'pakistan_weather_data-Sep2024-Oct2025.csv', 'RTA Data 2020 to July 2023.xlsx'])\n",
      "Processed path: ../data/processed/ (created if missing)\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely import from_wkt\n",
    "import openpyxl  # XLSX\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Paths (relative to root from src/)\n",
    "raw_path = \"../data/raw/\"\n",
    "processed_path = \"../data/processed/\"\n",
    "os.makedirs(processed_path, exist_ok=True)\n",
    "\n",
    "print(\"=== Data Cleaning Started ===\")\n",
    "print(f\"Raw path: {raw_path} (files: {os.listdir(raw_path)})\")\n",
    "print(f\"Processed path: {processed_path} (created if missing)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9f1aed-e2c9-466f-810c-b260f41e28b1",
   "metadata": {},
   "source": [
    "## **RTA Cleaning**\n",
    "- Drop missing CallTime (13%).\n",
    "- Parse datetime, filter 2020-2023.\n",
    "- incident_count = TotalPatientsInEmergency.fillna(1).\n",
    "- severity = PatientStatus.fillna('Unknown').\n",
    "- Proxy geo: Lahore center + jitter ±0.02° (~2km variance).\n",
    "- Filter Lahore bbox.\n",
    "- Output: cleaned_accidents.csv (shape ~40k)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bdde4aa-7b83-4b23-b616-5f72fc3cbcc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Cleaning RTA Accidents ===\n",
      "Raw shape: (40232, 30), Lahore shape: (40232, 5)\n",
      "Geo stats (post-jitter):\n",
      "          Latitude   Longitude\n",
      "count  40232.0000  40232.0000\n",
      "mean      31.5500     74.3501\n",
      "std        0.0200      0.0200\n",
      "min       31.4607     74.2607\n",
      "25%       31.5364     74.3366\n",
      "50%       31.5500     74.3501\n",
      "75%       31.5635     74.3636\n",
      "max       31.6396     74.4252\n",
      "Incident count stats:\n",
      " count    40232.000000\n",
      "mean         1.139068\n",
      "std          0.479940\n",
      "min          1.000000\n",
      "25%          1.000000\n",
      "50%          1.000000\n",
      "75%          1.000000\n",
      "max         15.000000\n",
      "Name: incident_count, dtype: float64\n",
      "✓ Saved cleaned_accidents.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Cleaning RTA Accidents ===\")\n",
    "rta_path = raw_path + \"RTA Data 2020 to July 2023.xlsx\"\n",
    "rta = pd.read_excel(rta_path)\n",
    "\n",
    "# Basic clean\n",
    "rta = rta.dropna(subset=['CallTime'])\n",
    "rta['datetime'] = pd.to_datetime(rta['CallTime'])\n",
    "rta = rta[rta['datetime'].dt.year.between(2020, 2023)]\n",
    "\n",
    "# Engineer features\n",
    "rta['incident_count'] = rta['TotalPatientsInEmergency'].fillna(1)\n",
    "rta['severity'] = rta['PatientStatus'].fillna('Unknown')\n",
    "\n",
    "# Lahore geo proxy (center + jitter for variance)\n",
    "np.random.seed(42)  # Reproducible\n",
    "base_lat, base_lon = 31.55, 74.35\n",
    "rta['Latitude'] = base_lat + np.random.normal(0, 0.02, len(rta))  # ~2km N-S jitter\n",
    "rta['Longitude'] = base_lon + np.random.normal(0, 0.02, len(rta))  # ~2km E-W jitter\n",
    "\n",
    "# Lahore bbox filter\n",
    "lahore_bounds = (31.4, 74.1, 31.7, 74.5)  # (min_lat, min_lon, max_lat, max_lon)\n",
    "rta_lahore = rta[\n",
    "    (rta['Latitude'].between(lahore_bounds[0], lahore_bounds[2])) &\n",
    "    (rta['Longitude'].between(lahore_bounds[1], lahore_bounds[3]))\n",
    "][['datetime', 'Latitude', 'Longitude', 'incident_count', 'severity']]\n",
    "\n",
    "print(f\"Raw shape: {rta.shape}, Lahore shape: {rta_lahore.shape}\")\n",
    "print(\"Geo stats (post-jitter):\\n\", rta_lahore[['Latitude', 'Longitude']].describe().round(4))\n",
    "print(\"Incident count stats:\\n\", rta_lahore['incident_count'].describe())\n",
    "\n",
    "# Save\n",
    "rta_lahore.to_csv(processed_path + \"cleaned_accidents.csv\", index=False)\n",
    "print(\"✓ Saved cleaned_accidents.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2be387-6974-4f1e-a1d6-1bc4c7ac9a03",
   "metadata": {},
   "source": [
    "## **Mobility Cleaning**\n",
    "- Concat 3 XLSXs.\n",
    "- Filter Punjab, 2020-2023.\n",
    "- Resample 15-min ffill.\n",
    "- mobility_proxy = workplaces_percent_change_from_baseline.fillna(0).\n",
    "- Output: cleaned_mobility.csv (shape ~93k)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6b0e9fc-e79d-45ee-b870-c278ac006449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Cleaning Mobility ===\n",
      "Raw concat shape: (20404, 16), Punjab resampled shape: (93409, 3)\n",
      "Head:\n",
      "                      workplaces_percent_change_from_baseline  transit_stations_percent_change_from_baseline  mobility_proxy\n",
      "datetime                                                                                                                   \n",
      "2020-02-15 00:00:00                                      2.0                                            4.0             2.0\n",
      "2020-02-15 00:15:00                                      2.0                                            4.0             2.0\n",
      "2020-02-15 00:30:00                                      2.0                                            4.0             2.0\n",
      "Mobility proxy stats:\n",
      " count    93409.000000\n",
      "mean         8.579077\n",
      "std         30.337160\n",
      "min        -79.000000\n",
      "25%         -9.000000\n",
      "50%          5.000000\n",
      "75%         38.000000\n",
      "max         63.000000\n",
      "Name: mobility_proxy, dtype: float64\n",
      "✓ Saved cleaned_mobility.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Cleaning Mobility ===\")\n",
    "files = [\n",
    "    raw_path + \"2020_PK_Region_Mobility_Report.xlsx\",\n",
    "    raw_path + \"2021_PK_Region_Mobility_Report.xlsx\",\n",
    "    raw_path + \"2022_PK_Region_Mobility_Report.xlsx\"\n",
    "]\n",
    "dfs = []\n",
    "for file in files:\n",
    "    df = pd.read_excel(file)\n",
    "    df['datetime'] = pd.to_datetime(df['date'])\n",
    "    dfs.append(df)\n",
    "mob_pk = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Filter\n",
    "mob_pk = mob_pk[mob_pk['datetime'].dt.year.between(2020, 2023)]\n",
    "mob_punjab = mob_pk[mob_pk['sub_region_1'] == 'Punjab'][\n",
    "    ['datetime', 'workplaces_percent_change_from_baseline', 'transit_stations_percent_change_from_baseline']\n",
    "]\n",
    "\n",
    "# Resample 15-min ffill\n",
    "mob_punjab = mob_punjab.set_index('datetime').resample('15min').ffill()\n",
    "mob_punjab['mobility_proxy'] = mob_punjab['workplaces_percent_change_from_baseline'].fillna(0)\n",
    "\n",
    "print(f\"Raw concat shape: {mob_pk.shape}, Punjab resampled shape: {mob_punjab.shape}\")\n",
    "print(\"Head:\\n\", mob_punjab.head(3).to_string())\n",
    "print(\"Mobility proxy stats:\\n\", mob_punjab['mobility_proxy'].describe())\n",
    "\n",
    "# Save\n",
    "mob_punjab.reset_index().to_csv(processed_path + \"cleaned_mobility.csv\", index=False)\n",
    "print(\"✓ Saved cleaned_mobility.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f4dcf2-9445-4260-ba82-b8998476494b",
   "metadata": {},
   "source": [
    "## **Weather Cleaning**\n",
    "- Concat 2 CSVs.\n",
    "- Parse datetime, filter Lahore 2020-2023.\n",
    "- Resample 15-min interpolate.\n",
    "- precip_lag = precipitation.shift(4).fillna(0) (~1hr lag).\n",
    "- Output: cleaned_weather.csv (shape ~140k)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1b67f9e-72e1-407b-a327-c5d0f4dcb1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Cleaning Weather ===\n",
      "Raw concat shape: (31779, 28), After NaT drop: 31779\n",
      "Datetime dtype: datetime64[ns]\n",
      "Lahore raw shape: 3288, Resampled shape: (140161, 8)\n",
      "Head:\n",
      "                          tavg  prcp   humidity  latitude  longitude  temperature  precipitation  precip_lag\n",
      "datetime                                                                                                   \n",
      "2020-01-01 00:00:00  6.200000   0.0  90.000000   31.5497    74.3436     6.200000            0.0         0.0\n",
      "2020-01-01 00:15:00  6.234375   0.0  89.947917   31.5497    74.3436     6.234375            0.0         0.0\n",
      "2020-01-01 00:30:00  6.268750   0.0  89.895833   31.5497    74.3436     6.268750            0.0         0.0\n",
      "Precip stats:\n",
      " count    140161.00\n",
      "mean          1.60\n",
      "std           4.14\n",
      "min           0.00\n",
      "25%           0.00\n",
      "50%           0.00\n",
      "75%           0.74\n",
      "max          42.60\n",
      "Name: precipitation, dtype: float64\n",
      "✓ Saved cleaned_weather.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Cleaning Weather ===\")\n",
    "w1_path = raw_path + \"pakistan_weather_2000_2024.csv\"\n",
    "w2_path = raw_path + \"pakistan_weather_data-Sep2024-Oct2025.csv\"\n",
    "w1 = pd.read_csv(w1_path)\n",
    "w2 = pd.read_csv(w2_path)\n",
    "\n",
    "# Parse datetime in each\n",
    "w1['datetime'] = pd.to_datetime(w1['date'], errors='coerce')\n",
    "w2['datetime'] = pd.to_datetime(w2['date'], errors='coerce')\n",
    "\n",
    "# Concat\n",
    "weather = pd.concat([w1, w2], ignore_index=True)\n",
    "\n",
    "# Re-parse after concat (fixes object dtype)\n",
    "weather['datetime'] = pd.to_datetime(weather['datetime'], errors='coerce')\n",
    "\n",
    "# Drop NaT now (after re-parse)\n",
    "weather = weather.dropna(subset=['datetime'])\n",
    "\n",
    "print(f\"Raw concat shape: {weather.shape}, After NaT drop: {len(weather)}\")\n",
    "print(f\"Datetime dtype: {weather['datetime'].dtype}\")  # Must be datetime64[ns]\n",
    "\n",
    "# Lahore filter & year range (.dt safe now)\n",
    "weather_lahore = weather[\n",
    "    (weather['city'].str.contains('Lahore', na=False, case=False)) &\n",
    "    (weather['datetime'].dt.year.between(2020, 2023))\n",
    "][['datetime', 'tavg', 'prcp', 'humidity', 'latitude', 'longitude']]\n",
    "\n",
    "# Resample 15-min interpolate\n",
    "weather_lahore = weather_lahore.set_index('datetime').resample('15T').interpolate(method='linear')\n",
    "weather_lahore['temperature'] = weather_lahore['tavg']\n",
    "weather_lahore['precipitation'] = weather_lahore['prcp']\n",
    "weather_lahore['precip_lag'] = weather_lahore['precipitation'].shift(4).fillna(weather_lahore['precipitation'].iloc[0])\n",
    "\n",
    "print(f\"Lahore raw shape: {len(weather[weather['city'].str.contains('Lahore', na=False, case=False)])}, Resampled shape: {weather_lahore.shape}\")\n",
    "print(\"Head:\\n\", weather_lahore.head(3).to_string())\n",
    "print(\"Precip stats:\\n\", weather_lahore['precipitation'].describe().round(2))\n",
    "\n",
    "# Save\n",
    "weather_lahore.reset_index().to_csv(processed_path + \"cleaned_weather.csv\", index=False)\n",
    "print(\"✓ Saved cleaned_weather.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e187da-292a-4788-a684-fc1190427601",
   "metadata": {},
   "source": [
    "## **Roads Cleaning**\n",
    "- Load gpd (.shp + .dbf).\n",
    "- Set CRS EPSG:4326, project to UTM 32643 for length (km).\n",
    "- Lahore bbox filter.\n",
    "- Add dummies (segment_id, highway='unknown', name='unnamed').\n",
    "- Output: cleaned_roads.csv (non-spatial/tabular for merge ; .shp for geospacial joins and visualizations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56339c09-6c0e-4f23-b8d1-68d8b9b4d6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Cleaning Roads ===\n",
      "Raw shape: (1077644, 16), Lahore cleaned shape: (79354, 17)\n",
      "Length stats:\n",
      " count    79354.0000\n",
      "mean         0.1781\n",
      "std          0.3048\n",
      "min          0.0005\n",
      "25%          0.0539\n",
      "50%          0.1038\n",
      "75%          0.1970\n",
      "max         20.0204\n",
      "Name: length, dtype: float64\n",
      "Head:\n",
      "          highway         name    length                                                                                                                      geometry\n",
      "227  residential         None  0.104746                                                                             LINESTRING (74.29559 31.47191, 74.29662 31.47157)\n",
      "228  residential         None  0.040637                                                                             LINESTRING (74.29684 31.47189, 74.29662 31.47157)\n",
      "229     tertiary  Ghazan Road  0.038187  LINESTRING (74.29924 31.46942, 74.29917 31.46932, 74.29913 31.46928, 74.2991 31.46923, 74.29907 31.46917, 74.29905 31.46912)\n",
      "✓ Saved cleaned_roads.csv and .shp\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Cleaning Roads ===\")\n",
    "os.environ['SHAPE_RESTORE_SHX'] = 'YES'  # SHX index\n",
    "roads_path = raw_path + \"hotosm_pak_roads_lines_shp.shp\"\n",
    "roads_gdf = gpd.read_file(roads_path)\n",
    "roads_gdf = roads_gdf.set_crs(\"EPSG:4326\", allow_override=True)\n",
    "\n",
    "# Project for accurate length\n",
    "roads_projected = roads_gdf.to_crs(\"EPSG:32643\")\n",
    "roads_projected[\"length\"] = roads_projected.geometry.length / 1000  # km\n",
    "roads_gdf = roads_projected.to_crs(\"EPSG:4326\")\n",
    "\n",
    "# Lahore bbox filter\n",
    "lahore_wkt = 'POLYGON((74.1 31.4, 74.5 31.4, 74.5 31.7, 74.1 31.7, 74.1 31.4))'\n",
    "lahore_poly = from_wkt(lahore_wkt)\n",
    "lahore_roads = roads_gdf[roads_gdf.intersects(lahore_poly)].copy()\n",
    "\n",
    "# Clean invalid/empty\n",
    "lahore_roads = lahore_roads[lahore_roads.geometry.is_valid & ~lahore_roads.geometry.is_empty]\n",
    "\n",
    "# Add dummies\n",
    "lahore_roads[\"segment_id\"] = range(len(lahore_roads))\n",
    "if 'highway' not in lahore_roads.columns:\n",
    "    lahore_roads[\"highway\"] = \"unknown\"\n",
    "if 'name' not in lahore_roads.columns:\n",
    "    lahore_roads[\"name\"] = \"unnamed\"\n",
    "\n",
    "print(f\"Raw shape: {roads_gdf.shape}, Lahore cleaned shape: {lahore_roads.shape}\")\n",
    "print(\"Length stats:\\n\", lahore_roads['length'].describe().round(4))\n",
    "print(\"Head:\\n\", lahore_roads.head(3)[['highway', 'name', 'length', 'geometry']].to_string() if 'highway' in lahore_roads.columns else lahore_roads.head(3).to_string())\n",
    "\n",
    "# Save (CSV for merge, .shp for geo)\n",
    "lahore_roads[['segment_id', 'highway', 'name', 'length']].to_csv(processed_path + \"cleaned_roads.csv\", index=False)\n",
    "lahore_roads.to_file(processed_path + \"cleaned_roads.shp\")\n",
    "print(\"✓ Saved cleaned_roads.csv and .shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa1ee72-aacc-4a64-8be7-8d6495e6f0b3",
   "metadata": {},
   "source": [
    "## **Cleaning Summary & Readiness Check**\n",
    "### Outputs Generated\n",
    "- **cleaned_accidents.csv**: 40k rows (Lahore jittered incidents, datetime/incident_count/severity/geo).\n",
    "- **cleaned_mobility.csv**: 93k rows (Punjab 15-min, mobility_proxy filled).\n",
    "- **cleaned_weather.csv**: 140k rows (Lahore 15-min, precip_lag engineered).\n",
    "- **cleaned_roads.csv**: 79k rows (Lahore bbox, length/highway dummies; .shp for geo).\n",
    "\n",
    "### Validation\n",
    "- All dtypes correct (datetime64[ns], float64 for nums).\n",
    "- No major data loss (e.g., 13% CallTime drop in RTA handled).\n",
    "- Geo variance good (std 0.02° for accidents; roads bbox filtered).\n",
    "- Temporal alignment: 15-min ready for merge.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
